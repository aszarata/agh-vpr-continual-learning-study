{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a25649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from src.utils.data import read_and_prepare_metadata\n",
    "from src.benchmarks.benchmark_factory import BenchmarkFactory\n",
    "from src.scenarios.task_splitters import TaskSplitter\n",
    "import src.models.torch_models as torch_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cfcc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT, IMG_SIZE = \"../dataset\", 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2ec949",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c53601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>camera_type</th>\n",
       "      <th>pass_no</th>\n",
       "      <th>location</th>\n",
       "      <th>class</th>\n",
       "      <th>role</th>\n",
       "      <th>split</th>\n",
       "      <th>class_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/DataSet_Xtion_RGB_train/000_Corridor1_RG...</td>\n",
       "      <td>Xtion</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>Corridor1</td>\n",
       "      <td>db</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/DataSet_Xtion_RGB_train/000_Corridor1_RG...</td>\n",
       "      <td>Xtion</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>Corridor1</td>\n",
       "      <td>db</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/DataSet_Xtion_RGB_train/001_Corridor1_RG...</td>\n",
       "      <td>Xtion</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 1.0)</td>\n",
       "      <td>Corridor1</td>\n",
       "      <td>db</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/DataSet_Xtion_RGB_train/001_Corridor1_RG...</td>\n",
       "      <td>Xtion</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 1.0)</td>\n",
       "      <td>Corridor1</td>\n",
       "      <td>db</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/DataSet_Xtion_RGB_train/002_Corridor1_RG...</td>\n",
       "      <td>Xtion</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 2.0)</td>\n",
       "      <td>Corridor1</td>\n",
       "      <td>db</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>test/DataSet_P40PRO_RGB_test3/078_F107_RGB_000...</td>\n",
       "      <td>P40PRO</td>\n",
       "      <td>3</td>\n",
       "      <td>(878.0, 878.0)</td>\n",
       "      <td>F107</td>\n",
       "      <td>query</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>test/DataSet_P40PRO_RGB_test3/079_F107_RGB_000...</td>\n",
       "      <td>P40PRO</td>\n",
       "      <td>3</td>\n",
       "      <td>(879.0, 879.0)</td>\n",
       "      <td>F107</td>\n",
       "      <td>query</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>test/DataSet_P40PRO_RGB_test3/081_F107_RGB_000...</td>\n",
       "      <td>P40PRO</td>\n",
       "      <td>3</td>\n",
       "      <td>(881.0, 881.0)</td>\n",
       "      <td>F107</td>\n",
       "      <td>query</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>test/DataSet_P40PRO_RGB_test3/082_F107_RGB_000...</td>\n",
       "      <td>P40PRO</td>\n",
       "      <td>3</td>\n",
       "      <td>(882.0, 882.0)</td>\n",
       "      <td>F107</td>\n",
       "      <td>query</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>test/DataSet_P40PRO_RGB_test3/084_F107_RGB_000...</td>\n",
       "      <td>P40PRO</td>\n",
       "      <td>3</td>\n",
       "      <td>(884.0, 884.0)</td>\n",
       "      <td>F107</td>\n",
       "      <td>query</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3306 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path camera_type  pass_no  \\\n",
       "0     train/DataSet_Xtion_RGB_train/000_Corridor1_RG...       Xtion        0   \n",
       "1     train/DataSet_Xtion_RGB_train/000_Corridor1_RG...       Xtion        0   \n",
       "2     train/DataSet_Xtion_RGB_train/001_Corridor1_RG...       Xtion        0   \n",
       "3     train/DataSet_Xtion_RGB_train/001_Corridor1_RG...       Xtion        0   \n",
       "4     train/DataSet_Xtion_RGB_train/002_Corridor1_RG...       Xtion        0   \n",
       "...                                                 ...         ...      ...   \n",
       "3301  test/DataSet_P40PRO_RGB_test3/078_F107_RGB_000...      P40PRO        3   \n",
       "3302  test/DataSet_P40PRO_RGB_test3/079_F107_RGB_000...      P40PRO        3   \n",
       "3303  test/DataSet_P40PRO_RGB_test3/081_F107_RGB_000...      P40PRO        3   \n",
       "3304  test/DataSet_P40PRO_RGB_test3/082_F107_RGB_000...      P40PRO        3   \n",
       "3305  test/DataSet_P40PRO_RGB_test3/084_F107_RGB_000...      P40PRO        3   \n",
       "\n",
       "            location      class   role  split  class_idx  \n",
       "0         (0.0, 0.0)  Corridor1     db  train          0  \n",
       "1         (0.0, 0.0)  Corridor1     db  train          0  \n",
       "2         (1.0, 1.0)  Corridor1     db  train          0  \n",
       "3         (1.0, 1.0)  Corridor1     db  train          0  \n",
       "4         (2.0, 2.0)  Corridor1     db  train          0  \n",
       "...              ...        ...    ...    ...        ...  \n",
       "3301  (878.0, 878.0)       F107  query   test          8  \n",
       "3302  (879.0, 879.0)       F107  query   test          8  \n",
       "3303  (881.0, 881.0)       F107  query   test          8  \n",
       "3304  (882.0, 882.0)       F107  query   test          8  \n",
       "3305  (884.0, 884.0)       F107  query   test          8  \n",
       "\n",
       "[3306 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = read_and_prepare_metadata(DATASET_ROOT)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a6d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aszarata/informatyka/magisterka/agh-continual-learning-study/notebooks/../src/scenarios/task_splitters.py:39: UserWarning: you are shuffling a 'StringArray' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(unique_keys)\n"
     ]
    }
   ],
   "source": [
    "splitter = TaskSplitter(\n",
    "    group_by=\"camera_type\"\n",
    ")\n",
    "benchmark_factory = BenchmarkFactory(DATASET_ROOT, IMG_SIZE)\n",
    "\n",
    "configs = splitter.split(df_meta)\n",
    "benchmark = benchmark_factory.build_img_classification_benchmark(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce868c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_0 = benchmark.train_datasets_stream[0].dataset\n",
    "valset_0 = benchmark.valid_datasets_stream[0].dataset\n",
    "testset_0 = benchmark.test_datasets_stream[0].dataset\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset_0, batch_size=16, shuffle=True)\n",
    "valloader = DataLoader(valset_0, batch_size=16, shuffle=True)\n",
    "testloader = DataLoader(testset_0, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1daf6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "  Class 0: 54 (12.1%)\n",
      "  Class 1: 44 (9.9%)\n",
      "  Class 2: 49 (11.0%)\n",
      "  Class 3: 52 (11.7%)\n",
      "  Class 4: 55 (12.3%)\n",
      "  Class 5: 46 (10.3%)\n",
      "  Class 6: 44 (9.9%)\n",
      "  Class 7: 51 (11.4%)\n",
      "  Class 8: 51 (11.4%)\n",
      "  Imbalance ratio: 1.2\n",
      "\n",
      "Val:\n",
      "  Class 0: 3 (3.8%)\n",
      "  Class 1: 12 (15.4%)\n",
      "  Class 2: 5 (6.4%)\n",
      "  Class 3: 10 (12.8%)\n",
      "  Class 4: 7 (9.0%)\n",
      "  Class 5: 14 (17.9%)\n",
      "  Class 6: 7 (9.0%)\n",
      "  Class 7: 11 (14.1%)\n",
      "  Class 8: 9 (11.5%)\n",
      "  Imbalance ratio: 4.7\n"
     ]
    }
   ],
   "source": [
    "def check_balance(dataset, name):\n",
    "    from collections import Counter\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        labels.append(label)\n",
    "    \n",
    "    counts = Counter(labels)\n",
    "    print(f\"\\n{name}:\")\n",
    "    for cls in sorted(counts):\n",
    "        print(f\"  Class {cls}: {counts[cls]} ({counts[cls]/len(labels):.1%})\")\n",
    "    \n",
    "    imbalance = max(counts.values()) / min(counts.values())\n",
    "    print(f\"  Imbalance ratio: {imbalance:.1f}\")\n",
    "\n",
    "check_balance(trainset_0, \"Train\")\n",
    "check_balance(valset_0, \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2c1774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch_models.get_resnet34_for_cl(9, False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 40\n",
    "early_stopping_patience = 5\n",
    "scheduler_patience = 3\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5b0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.6,)\n",
    "scheduler = scheduler.ReduceLROnPlateau(optimizer, patience=scheduler_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6874acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:14<00:00,  1.99it/s, loss=1.93]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.43it/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 2.16718151313918 | Val loss: 2.4041367053985594 | Val acc: 3.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.11it/s, loss=1.4] \n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=9.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss: 1.599706185715539 | Val loss: 9.38684253692627 | Val acc: 12.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.10it/s, loss=1.47] \n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=3.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train loss: 1.53902268409729 | Val loss: 3.5099470138549806 | Val acc: 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.922]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=25.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train loss: 1.2703914025000163 | Val loss: 22.996303939819335 | Val acc: 15.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.961]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=7.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train loss: 1.05394370002406 | Val loss: 8.903261661529541 | Val acc: 7.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.446]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.51it/s, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train loss: 0.7917410827108792 | Val loss: 0.8106581568717957 | Val acc: 69.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.3]  \n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train loss: 0.7045936222587313 | Val loss: 0.7083677649497986 | Val acc: 75.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=1.24] \n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.51it/s, loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train loss: 0.5957847514322826 | Val loss: 0.6448321461677551 | Val acc: 79.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.11it/s, loss=0.641]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train loss: 0.6023848525115422 | Val loss: 0.6372695207595825 | Val acc: 74.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.633]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train loss: 0.5984169127685683 | Val loss: 0.5613492965698242 | Val acc: 85.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.09it/s, loss=0.292]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train loss: 0.5713890045881271 | Val loss: 0.6263146996498108 | Val acc: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.08it/s, loss=0.586]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train loss: 0.5026800472821508 | Val loss: 0.5737219154834747 | Val acc: 82.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.06it/s, loss=0.256]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train loss: 0.483133393738951 | Val loss: 0.585549196600914 | Val acc: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.10it/s, loss=0.284]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.53it/s, loss=0.485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train loss: 0.4967735542782715 | Val loss: 0.5510011672973633 | Val acc: 83.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.215]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train loss: 0.44902823705758366 | Val loss: 0.5103236973285675 | Val acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.364]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train loss: 0.424490928117718 | Val loss: 0.5583840012550354 | Val acc: 83.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.105]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train loss: 0.45418020790176733 | Val loss: 0.5064693450927734 | Val acc: 83.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.13it/s, loss=0.274]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.51it/s, loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train loss: 0.39465545809694696 | Val loss: 0.48400182723999025 | Val acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.284]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.46it/s, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train loss: 0.42481520026922226 | Val loss: 0.5085803389549255 | Val acc: 85.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.415]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.51it/s, loss=0.571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train loss: 0.4687000906893185 | Val loss: 0.4443419247865677 | Val acc: 85.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.369]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=0.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train loss: 0.3807314299046993 | Val loss: 0.4849394798278809 | Val acc: 82.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.07it/s, loss=0.295]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.35it/s, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train loss: 0.36697967084390776 | Val loss: 0.4998082756996155 | Val acc: 85.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.10it/s, loss=0.371]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train loss: 0.41634515087519375 | Val loss: 0.4938217043876648 | Val acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.514]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train loss: 0.3448142797819206 | Val loss: 0.42918062806129453 | Val acc: 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.691]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.47it/s, loss=0.22] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train loss: 0.3907202551407473 | Val loss: 0.45577242970466614 | Val acc: 85.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.869]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.50it/s, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train loss: 0.3594052605330944 | Val loss: 0.46664246916770935 | Val acc: 87.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.12it/s, loss=0.416]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.51it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train loss: 0.35603555185454233 | Val loss: 0.4729055404663086 | Val acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.11it/s, loss=0.353] \n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.37it/s, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train loss: 0.33362487171377453 | Val loss: 0.4885295003652573 | Val acc: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [00:13<00:00,  2.09it/s, loss=0.188]\n",
      "Validation: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=0.563]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train loss: 0.2972405898783888 | Val loss: 0.4600228786468506 | Val acc: 84.62%\n",
      "Early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps_no_progress = 0\n",
    "best_val_loss = 10**10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    with tqdm(trainloader, desc=\"Training\") as pbar:\n",
    "        for (X, y) in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        with tqdm(valloader, desc=\"Validation\") as pbar:\n",
    "            for (X, y) in pbar:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_pred = model(X)\n",
    "                \n",
    "                loss = criterion(y_pred, y)\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(y_pred.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "\n",
    "    train_loss = total_train_loss / len(trainloader)\n",
    "    val_loss = total_val_loss / len(valloader)\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    steps_no_progress += 1\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        steps_no_progress = 0\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Train loss: {train_loss} | Val loss: {val_loss} | Val acc: {val_acc:.2f}%\")\n",
    "    if steps_no_progress >= early_stopping_patience:\n",
    "        print(\"Early stop\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b307415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"../models/ResNet34-camera-task-0-2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4397908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch_models.get_resnet34_for_cl(9, False)\n",
    "loaded_model.load_state_dict(torch.load( \"../models/BEST-ResNet34-camera-task-0-2.pth\"))\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c33a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tests: 100%|██████████| 9/9 [00:01<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 7  0  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0  0  0]\n",
      " [ 4  0 12  0  0  1  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0]\n",
      " [ 1  0  0  0 14  2  0  0  1]\n",
      " [ 0  0  0  0  0 18  0  0  1]\n",
      " [ 0  0  0  0  1  0  9  5  0]\n",
      " [ 0  0  0  0  0  0  1 14  3]\n",
      " [ 2  0  0  0  0  1  0  1 10]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    1.0000    0.6667         7\n",
      "           1     1.0000    1.0000    1.0000        14\n",
      "           2     1.0000    0.7059    0.8276        17\n",
      "           3     1.0000    1.0000    1.0000         9\n",
      "           4     0.9333    0.7778    0.8485        18\n",
      "           5     0.8182    0.9474    0.8780        19\n",
      "           6     0.9000    0.6000    0.7200        15\n",
      "           7     0.7000    0.7778    0.7368        18\n",
      "           8     0.6667    0.7143    0.6897        14\n",
      "\n",
      "    accuracy                         0.8168       131\n",
      "   macro avg     0.8354    0.8359    0.8186       131\n",
      "weighted avg     0.8495    0.8168    0.8199       131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "loaded_model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(testloader, \"Tests\") as pbar:\n",
    "        for X_test, y_test in pbar:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            output = loaded_model(X_test)\n",
    "            pred = output.argmax(dim=1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(y_test.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(all_targets, all_preds, digits=4)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc90234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agh-continual-learning-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
